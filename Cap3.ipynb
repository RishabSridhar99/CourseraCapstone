{"cells": [{"metadata": {}, "cell_type": "code", "source": "from bs4 import BeautifulSoup\nimport json # library to handle JSON files\nimport numpy as np\nimport pandas as pd\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport urllib\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\n", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Solving environment: / ", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "pd.options.display.max_rows = 4000", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "First we'll use Beautiful soup to parse the wikipedia page"}, {"metadata": {}, "cell_type": "code", "source": "url='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "response = urllib.request.urlopen(url)\nrawhtml = response.read()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "soup = BeautifulSoup(rawhtml, 'html.parser')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pclist = []\nfor table_row in soup.select(\"table.wikitable tr\"):\n    cells = table_row.findAll('td')\n    #row = [table_row.text.strip() for table_row in cells]\n    #pclist.append(row)\n    #note: do not include \"Not assigned\" values or grayed out values\n    if len(cells) > 0:\n        pc = cells[0].text.strip()\n        b = cells[1].text.strip()\n        n = cells[2].text.strip()\n\n        if (b == \"Not assigned\" and n==\"Not assigned\"):\n           #skip row\n            a=\"skipping\"\n            #print('skipping')\n       # elif (b == \"Not assigned\"):\n       #     pclist.append([pc,n,n])\n        elif(n==\"Not assigned\"):\n            #if the neighbourhood is not assigned, then subsitute in the borough\n            pclist.append([pc,b,b])\n        else:\n            pclist.append([pc,b,n])\n            \n\ntoronto_df = pd.DataFrame(pclist, columns=[\"FSA\", \"Borough\", \"Neighborhood\"])\ntoronto_df = toronto_df.sort_values(by=['FSA'])\ntoronto_df.head(15)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_df.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pclist = []\nprevPC = \"\" # stores the previous postal code to see if we need to append neighbourhoods or create a new row\ncurrNeighbourhoods = \"\"\nprevBorough = \"\"\nfor table_row in soup.select(\"table.wikitable tr\"):\n    cells = table_row.findAll('td')\n    if len(cells) > 0:\n        pc = cells[0].text.strip()\n        b = cells[1].text.strip()\n        n = cells[2].text.strip()\n        if ((b == \"Not assigned\" and n==\"Not assigned\") or b == \"blank\"):\n           #skip row\n            a=\"skipping\"\n        else:\n            if (n==\"Not assigned\"):\n                n = b; # set the neighbourhood equal to the borough\n            \n            if (pc == prevPC):\n                # append neighbourhoods into comma delimited string\n                currNeighbourhoods = currNeighbourhoods + \", \" + n\n                 \n            else:\n                # new postal code, so write out previous row\n                if (prevPC != \"\"):\n                    pclist.append([prevPC,prevBorough,currNeighbourhoods])\n                prevPC = pc # set a new PrevPC value for next loop\n                prevBorough = b\n                currNeighbourhoods = n # start a new neighbourhoods string\n# write out last row\npclist.append([prevPC,prevBorough,currNeighbourhoods])               \n            \ntoronto_df = pd.DataFrame(pclist, columns=[\"PostalCode\", \"Borough\", \"Neighborhood\"])\ntoronto_df = toronto_df.sort_values(by=['PostalCode'])#.reset_index()\ntoronto_df#.head(15)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_df.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install geocoder\nimport geocoder", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "lat_lng_coords = None\n# create lists to store our new lats and longs\nlats = []\nlongs=[]\n#loop through our dataframe and look up the lat/long of each postal code\nfor index, row in toronto_df.iterrows():\n    #print (row[\"PostalCode\"])\n    postal_code=row[\"PostalCode\"]\n    # loop until you get the coordinates\n    lat_lng_coords = None\n    while(lat_lng_coords is None):\n        g = geocoder.google('{}, Toronto, Ontario'.format(postal_code))\n        lat_lng_coords = g.latlng\n\n    #latitude = lat_lng_coords[0]\n    #longitude = lat_lng_coords[1]\n    lats.append(lat_lng_coords[0])\n    longs.append(lat_lng_coords[1])\n    #print ('postal code {} had latitude {} and longitude {}'.format(postal_code, latitude, longitude))\n\ntoronto_df['Latitude'] = lats\ntoronto_df['Longitude'] = longs\ntoronto_df.head() #preview our results\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "address = 'Toronto, ON'\n\ngeolocator = Nominatim()\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Toronto are {}, {}.'.format(latitude, longitude))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "map_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(toronto_df['Latitude'], toronto_df['Longitude'], toronto_df['Borough'], toronto_df['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(map_toronto)\n        #parse_html=False).add_to(map_newyork)  \n    \nmap_toronto\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_data = toronto_df[toronto_df['Borough'].str.contains('Toronto')].reset_index(drop=True)\ntoronto_data.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "latitude = toronto_data.iat[1,3]\nlongitude = toronto_data.iat[1,4]\nlatitude", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "latitude = toronto_data.iat[1,3]\nlongitude = toronto_data.iat[1,4]\nmap_toronto2 = folium.Map(location=[latitude, longitude], zoom_start=13)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(toronto_data['Latitude'], toronto_data['Longitude'], toronto_data['Borough'], toronto_data['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(map_toronto2)\n\n    \nmap_toronto2\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "neighbourhood = toronto_data.iat[1,2]\n# we already have the lat and long from previous section\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighbourhood, \n                                                              latitude, \n                                                               longitude))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "LIMIT=100\nradius = 500\n# type your answer here\nurl='https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n        CLIENT_ID,CLIENT_SECRET,VERSION,\n        latitude,longitude,\n        radius, \n    LIMIT)\nprint(url)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "results = requests.get(url).json()\nresults", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_venues = getNearbyVenues(names=toronto_data['Neighborhood'],latitudes=toronto_data['Latitude'],longitudes=toronto_data['Longitude'])\ntoronto_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(toronto_venues.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_venues.groupby('Neighborhood').count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))\nThere are 232 uniques categories.\nNow we will analyze each neighbourhood\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# one hot encoding\ntoronto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\ntoronto_onehot['Neighborhood'] = toronto_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [toronto_onehot.columns[-1]] + list(toronto_onehot.columns[:-1])\nmanhattan_onehot = toronto_onehot[fixed_columns]\n\ntoronto_onehot.head()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_onehot.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_grouped = toronto_onehot.groupby('Neighborhood').mean().reset_index()\ntoronto_grouped", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_grouped.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 5\n\nfor hood in toronto_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = toronto_grouped[toronto_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')\n\n\n\nnow put that data into a dataframe for furhter analysis\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "um_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = toronto_grouped['Neighborhood']\n\nfor ind in np.arange(toronto_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(toronto_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now let's cluster the neighbourhoods\nwe'll use K-means algorithm and will start by clustering into 5 groups\n"}, {"metadata": {}, "cell_type": "code", "source": "# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged = toronto_data\n\n# add clustering labels\ntoronto_merged['Cluster Labels'] = kmeans.labels_\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\ntoronto_merged.head() # check the last columns!\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# create map to visualize the clusters\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i+x+(i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 0, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 1, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 2, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 3, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_merged.loc[toronto_merged['Cluster Labels'] == 4, toronto_merged.columns[[2] + list(range(5, toronto_merged.shape[1]))]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}